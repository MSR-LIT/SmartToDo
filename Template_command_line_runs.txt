
BERT AS SERCIVE :

(project) C:\Users\t-sumu\Desktop\Project_2k19\CodeRepo\bert_as_service>bert-serving-start -model_dir tmp\english_L-12_H-768_A-12\ -num_worker=1 -max_seq_len NONE -pooling_strategy REDUCE_MEAN

Running Fine tuned BERT :

bert-serving-start -model_dir tmp\english_L-12_H-768_A-12\ -num_worker=1 -max_seq_len NONE -pooling_strategy REDUCE_MEAN -tuned_model_dir=tmp\commitment\ -ckpt_name=model.ckpt-510 -pooling_layer=-2

bert-serving-start -model_dir tmp\english_L-12_H-768_A-12\ -num_worker=1 -max_seq_len NONE -pooling_strategy REDUCE_MEAN_MAX -tuned_model_dir=tmp\commitment\ -ckpt_name=model.ckpt-510 -pooling_layer=-1 -mask_cls_sep


Running the models on entire dataset in the server :   

(1) Creating vocabulary - Orig 

python preprocess.py -train_src Orig_seq2seq_final_data/avocado.bert_tokenized/src-train.txt -train_tgt Orig_seq2seq_final_data/avocado.bert_tokenized/tgt-train.txt -valid_src Orig_seq2seq_final_data/avocado.bert_tokenized/src-valid.txt -valid_tgt Orig_seq2seq_final_data/avocado.bert_tokenized/tgt-valid.txt -save_data processed_final/avocado.bert_tokenized.shared.copy --share_vocab --src_seq_length 256 --src_words_min_frequency 2 --tgt_words_min_frequency 2 --dynamic_dict


python preprocess.py -train_src Orig_seq2seq_final_data/avocado.bert_tokenized/src-train.txt -train_tgt Orig_seq2seq_final_data/avocado.bert_tokenized/tgt-train.txt -valid_src Orig_seq2seq_final_data/avocado.bert_tokenized/src-valid.txt -valid_tgt Orig_seq2seq_final_data/avocado.bert_tokenized/tgt-valid.txt -save_data processed_final/avocado.bert_tokenized.separate.copy --src_seq_length 256 --src_words_min_frequency 2 --tgt_words_min_frequency 2 --dynamic_dict


python preprocess.py -train_src Orig_seq2seq_final_data/avocado.spacy_tokenized/src-train.txt -train_tgt Orig_seq2seq_final_data/avocado.spacy_tokenized/tgt-train.txt -valid_src Orig_seq2seq_final_data/avocado.spacy_tokenized/src-valid.txt -valid_tgt Orig_seq2seq_final_data/avocado.spacy_tokenized/tgt-valid.txt -save_data processed_final/avocado.spacy_tokenized.shared.copy --share_vocab --src_seq_length 256 --src_words_min_frequency 2 --tgt_words_min_frequency 2 --dynamic_dict


python preprocess.py -train_src Orig_seq2seq_final_data/avocado.spacy_tokenized/src-train.txt -train_tgt Orig_seq2seq_final_data/avocado.spacy_tokenized/tgt-train.txt -valid_src Orig_seq2seq_final_data/avocado.spacy_tokenized/src-valid.txt -valid_tgt Orig_seq2seq_final_data/avocado.spacy_tokenized/tgt-valid.txt -save_data processed_final/avocado.spacy_tokenized.separate.copy --src_seq_length 256 --src_words_min_frequency 2 --tgt_words_min_frequency 2 --dynamic_dict


python preprocess.py -train_src Orig_seq2seq_final_data/avocado.bert_tokenized/src-train.txt -train_tgt Orig_seq2seq_final_data/avocado.bert_tokenized/tgt-train.txt -valid_src Orig_seq2seq_final_data/avocado.bert_tokenized/src-valid.txt -valid_tgt Orig_seq2seq_final_data/avocado.bert_tokenized/tgt-valid.txt -save_data processed_final/avocado.bert_tokenized.vanilla --share_vocab --src_seq_length 256 --src_words_min_frequency 2 --tgt_words_min_frequency 2 --dynamic_dict


python preprocess.py -train_src Orig_seq2seq_final_data/avocado.spacy_tokenized/src-train.txt -train_tgt Orig_seq2seq_final_data/avocado.spacy_tokenized/tgt-train.txt -valid_src Orig_seq2seq_final_data/avocado.spacy_tokenized/src-valid.txt -valid_tgt Orig_seq2seq_final_data/avocado.spacy_tokenized/tgt-valid.txt -save_data processed_final/avocado.spacy_tokenized.vanilla --share_vocab --src_seq_length 256 --src_words_min_frequency 2 --tgt_words_min_frequency 2 --dynamic_dict

(2) Word-embeddings look up from Glove - Orig 


python ./tools/embeddings_to_torch.py -emb_file_enc "./glove_dir/glove.6B/glove.6B.100d.txt" -emb_file_dec "./glove_dir/glove.6B/glove.6B.100d.txt" -dict_file "processed_final/avocado.bert_tokenized.shared.copy.vocab.pt" -output_file "processed_final/avocado.bert_tokenized.shared.copy.embeddings.d100"

python ./tools/embeddings_to_torch.py -emb_file_enc "./glove_dir/glove.6B/glove.6B.100d.txt" -emb_file_dec "./glove_dir/glove.6B/glove.6B.100d.txt" -dict_file "processed_final/avocado.bert_tokenized.separate.copy.vocab.pt" -output_file "processed_final/avocado.bert_tokenized.separate.copy.embeddings.d100"

python ./tools/embeddings_to_torch.py -emb_file_enc "./glove_dir/glove.840B/glove.840B.300d.txt" -emb_file_dec "./glove_dir/glove.840B/glove.840B.300d.txt" -dict_file "processed_final/avocado.bert_tokenized.shared.copy.vocab.pt" -output_file "processed_final/avocado.bert_tokenized.shared.copy.embeddings.d300"

python ./tools/embeddings_to_torch.py -emb_file_enc "./glove_dir/glove.840B/glove.840B.300d.txt" -emb_file_dec "./glove_dir/glove.840B/glove.840B.300d.txt" -dict_file "processed_final/avocado.bert_tokenized.separate.copy.vocab.pt" -output_file "processed_final/avocado.bert_tokenized.separate.copy.embeddings.d300"


python ./tools/embeddings_to_torch.py -emb_file_enc "./glove_dir/glove.6B/glove.6B.100d.txt" -emb_file_dec "./glove_dir/glove.6B/glove.6B.100d.txt" -dict_file "processed_final/avocado.spacy_tokenized.shared.copy.vocab.pt" -output_file "processed_final/avocado.spacy_tokenized.shared.copy.embeddings.d100"

python ./tools/embeddings_to_torch.py -emb_file_enc "./glove_dir/glove.6B/glove.6B.100d.txt" -emb_file_dec "./glove_dir/glove.6B/glove.6B.100d.txt" -dict_file "processed_final/avocado.spacy_tokenized.separate.copy.vocab.pt" -output_file "processed_final/avocado.spacy_tokenized.separate.copy.embeddings.d100"

python ./tools/embeddings_to_torch.py -emb_file_enc "./glove_dir/glove.840B/glove.840B.300d.txt" -emb_file_dec "./glove_dir/glove.840B/glove.840B.300d.txt" -dict_file "processed_final/avocado.spacy_tokenized.shared.copy.vocab.pt" -output_file "processed_final/avocado.spacy_tokenized.shared.copy.embeddings.d300"


python ./tools/embeddings_to_torch.py -emb_file_enc "./glove_dir/glove.840B/glove.840B.300d.txt" -emb_file_dec "./glove_dir/glove.840B/glove.840B.300d.txt" -dict_file "processed_final/avocado.spacy_tokenized.separate.copy.vocab.pt" -output_file "processed_final/avocado.spacy_tokenized.separate.copy.embeddings.d300"


python ./tools/embeddings_to_torch.py -emb_file_enc "./glove_dir/glove.6B/glove.6B.100d.txt" -emb_file_dec "./glove_dir/glove.6B/glove.6B.100d.txt" -dict_file "processed_final/avocado.bert_tokenized.vanilla.vocab.pt" -output_file "processed_final/avocado.bert_tokenized.vanilla.embeddings.d100"

python ./tools/embeddings_to_torch.py -emb_file_enc "./glove_dir/glove.840B/glove.840B.300d.txt" -emb_file_dec "./glove_dir/glove.840B/glove.840B.300d.txt" -dict_file "processed_final/avocado.bert_tokenized.vanilla.vocab.pt" -output_file "processed_final/avocado.bert_tokenized.vanilla.embeddings.d300"

python ./tools/embeddings_to_torch.py -emb_file_enc "./glove_dir/glove.6B/glove.6B.100d.txt" -emb_file_dec "./glove_dir/glove.6B/glove.6B.100d.txt" -dict_file "processed_final/avocado.spacy_tokenized.vanilla.vocab.pt" -output_file "processed_final/avocado.spacy_tokenized.vanilla.embeddings.d100"

python ./tools/embeddings_to_torch.py -emb_file_enc "./glove_dir/glove.840B/glove.840B.300d.txt" -emb_file_dec "./glove_dir/glove.840B/glove.840B.300d.txt" -dict_file "processed_final/avocado.spacy_tokenized.vanilla.vocab.pt" -output_file "processed_final/avocado.spacy_tokenized.vanilla.embeddings.d300"



(3) Create config files and run them -  Orig 

CUDA_VISIBLE_DEVICES=0 python train.py --config Orig_config_final/<tokenizer>/config-<index>.yml


********************************************************************************************************************************************************

(1) Creating vocabulary - BiFocal

python preprocess.py -train_src BiFocal_seq2seq_final_data/avocado.bert_tokenized/src-train.txt -train_qry BiFocal_seq2seq_final_data/avocado.bert_tokenized/qry-train.txt -train_tgt BiFocal_seq2seq_final_data/avocado.bert_tokenized/tgt-train.txt -valid_src BiFocal_seq2seq_final_data/avocado.bert_tokenized/src-valid.txt -valid_qry BiFocal_seq2seq_final_data/avocado.bert_tokenized/qry-valid.txt -valid_tgt BiFocal_seq2seq_final_data/avocado.bert_tokenized/tgt-valid.txt -save_data processed_final/avocado.bert_tokenized.shared.copy --share_vocab --src_seq_length 256 --qry_seq_length 256 --src_words_min_frequency 2 --qry_words_min_frequency 2 --tgt_words_min_frequency 2 --dynamic_dict


python preprocess.py -train_src BiFocal_seq2seq_final_data/avocado.bert_tokenized/src-train.txt -train_qry BiFocal_seq2seq_final_data/avocado.bert_tokenized/qry-train.txt -train_tgt BiFocal_seq2seq_final_data/avocado.bert_tokenized/tgt-train.txt -valid_src BiFocal_seq2seq_final_data/avocado.bert_tokenized/src-valid.txt -valid_qry BiFocal_seq2seq_final_data/avocado.bert_tokenized/qry-valid.txt -valid_tgt BiFocal_seq2seq_final_data/avocado.bert_tokenized/tgt-valid.txt -save_data processed_final/avocado.bert_tokenized.separate.copy --src_seq_length 256 --qry_seq_length 256 --src_words_min_frequency 2 --qry_words_min_frequency 2 --tgt_words_min_frequency 2 --dynamic_dict


python preprocess.py -train_src BiFocal_seq2seq_final_data/avocado.spacy_tokenized/src-train.txt -train_qry BiFocal_seq2seq_final_data/avocado.spacy_tokenized/qry-train.txt -train_tgt BiFocal_seq2seq_final_data/avocado.spacy_tokenized/tgt-train.txt -valid_src BiFocal_seq2seq_final_data/avocado.spacy_tokenized/src-valid.txt -valid_qry BiFocal_seq2seq_final_data/avocado.spacy_tokenized/qry-valid.txt -valid_tgt BiFocal_seq2seq_final_data/avocado.spacy_tokenized/tgt-valid.txt -save_data processed_final/avocado.spacy_tokenized.shared.copy --share_vocab --src_seq_length 256 --qry_seq_length 256 --src_words_min_frequency 2 --qry_words_min_frequency 2 --tgt_words_min_frequency 2 --dynamic_dict


python preprocess.py -train_src BiFocal_seq2seq_final_data/avocado.spacy_tokenized/src-train.txt -train_qry BiFocal_seq2seq_final_data/avocado.spacy_tokenized/qry-train.txt -train_tgt BiFocal_seq2seq_final_data/avocado.spacy_tokenized/tgt-train.txt -valid_src BiFocal_seq2seq_final_data/avocado.spacy_tokenized/src-valid.txt -valid_qry BiFocal_seq2seq_final_data/avocado.spacy_tokenized/qry-valid.txt -valid_tgt BiFocal_seq2seq_final_data/avocado.spacy_tokenized/tgt-valid.txt -save_data processed_final/avocado.spacy_tokenized.separate.copy --src_seq_length 256 --qry_seq_length 256 --src_words_min_frequency 2 --qry_words_min_frequency 2 --tgt_words_min_frequency 2 --dynamic_dict


(2) Word-embeddings look up from Glove - BiFocal


python ./tools/embeddings_to_torch.py -emb_file_enc "../OpenNMT-py/glove_dir/glove.6B/glove.6B.100d.txt" -emb_file_match "../OpenNMT-py/glove_dir/glove.6B/glove.6B.100d.txt" -emb_file_dec "../OpenNMT-py/glove_dir/glove.6B/glove.6B.100d.txt" -dict_file "processed_final/avocado.bert_tokenized.shared.copy.vocab.pt" -output_file "processed_final/avocado.bert_tokenized.shared.copy.embeddings.d100"

python ./tools/embeddings_to_torch.py -emb_file_enc "../OpenNMT-py/glove_dir/glove.6B/glove.6B.100d.txt" -emb_file_match "../OpenNMT-py/glove_dir/glove.6B/glove.6B.100d.txt" -emb_file_dec "../OpenNMT-py/glove_dir/glove.6B/glove.6B.100d.txt" -dict_file "processed_final/avocado.bert_tokenized.separate.copy.vocab.pt" -output_file "processed_final/avocado.bert_tokenized.separate.copy.embeddings.d100"


python ./tools/embeddings_to_torch.py -emb_file_enc "../OpenNMT-py/glove_dir/glove.6B/glove.6B.100d.txt" -emb_file_match "../OpenNMT-py/glove_dir/glove.6B/glove.6B.100d.txt" -emb_file_dec "../OpenNMT-py/glove_dir/glove.6B/glove.6B.100d.txt" -dict_file "processed_final/avocado.spacy_tokenized.shared.copy.vocab.pt" -output_file "processed_final/avocado.spacy_tokenized.shared.copy.embeddings.d100"


python ./tools/embeddings_to_torch.py -emb_file_enc "../OpenNMT-py/glove_dir/glove.6B/glove.6B.100d.txt" -emb_file_match "../OpenNMT-py/glove_dir/glove.6B/glove.6B.100d.txt" -emb_file_dec "../OpenNMT-py/glove_dir/glove.6B/glove.6B.100d.txt" -dict_file "processed_final/avocado.spacy_tokenized.separate.copy.vocab.pt" -output_file "processed_final/avocado.spacy_tokenized.separate.copy.embeddings.d100"


python ./tools/embeddings_to_torch.py -emb_file_enc "../OpenNMT-py/glove_dir/glove.840B/glove.840B.300d.txt" -emb_file_match "../OpenNMT-py/glove_dir/glove.840B/glove.840B.300d.txt" -emb_file_dec "../OpenNMT-py/glove_dir/glove.840B/glove.840B.300d.txt" -dict_file "processed_final/avocado.bert_tokenized.shared.copy.vocab.pt" -output_file "processed_final/avocado.bert_tokenized.shared.copy.embeddings.d300"

python ./tools/embeddings_to_torch.py -emb_file_enc "../OpenNMT-py/glove_dir/glove.840B/glove.840B.300d.txt" -emb_file_match "../OpenNMT-py/glove_dir/glove.840B/glove.840B.300d.txt" -emb_file_dec "../OpenNMT-py/glove_dir/glove.840B/glove.840B.300d.txt" -dict_file "processed_final/avocado.bert_tokenized.separate.copy.vocab.pt" -output_file "processed_final/avocado.bert_tokenized.separate.copy.embeddings.d300"


python ./tools/embeddings_to_torch.py -emb_file_enc "../OpenNMT-py/glove_dir/glove.840B/glove.840B.300d.txt" -emb_file_match "../OpenNMT-py/glove_dir/glove.840B/glove.840B.300d.txt" -emb_file_dec "../OpenNMT-py/glove_dir/glove.840B/glove.840B.300d.txt" -dict_file "processed_final/avocado.spacy_tokenized.shared.copy.vocab.pt" -output_file "processed_final/avocado.spacy_tokenized.shared.copy.embeddings.d300"

python ./tools/embeddings_to_torch.py -emb_file_enc "../OpenNMT-py/glove_dir/glove.840B/glove.840B.300d.txt" -emb_file_match "../OpenNMT-py/glove_dir/glove.840B/glove.840B.300d.txt" -emb_file_dec "../OpenNMT-py/glove_dir/glove.840B/glove.840B.300d.txt" -dict_file "processed_final/avocado.spacy_tokenized.separate.copy.vocab.pt" -output_file "processed_final/avocado.spacy_tokenized.separate.copy.embeddings.d300"

(3) Create config files and run them -  BiFocal

CUDA_VISIBLE_DEVICES=0 python train.py --config BiFocal_config_final/<tokenizer>/config-<index>.yml